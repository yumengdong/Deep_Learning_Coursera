# Deep_Learning_Coursera
Deep Learning Specialization on Coursera

## Course 1. Neural Networks and Deep Learning
- <A href='http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week2/Python%20Basics%20With%20Numpy%20v3.html'>Python Basics with Numpy</A><BR>
  - Implement basic core deep learning functions such as sigmoid, softwamx
  - Use vectorization instead of for-loops and while-loops

- <A href='http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week2/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset%20v5.html'>Logistic Regression with a Neural Network mindset</A><BR>
  - Build a logistic regression classifier to recognize cats
  - Compare the model prediction accuracy and learning curve with several choices of learning rates
  
- <A href='http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week3/Planar%20data%20classification%20with%20one%20hidden%20layer%20v5.html'>Planar Data Classification with One Hidden Layer </A><BR>  
  - Build 2-layer neural network to classify red and blue points of flower dataset
  - Compare the model prediction accuracy with the Simple Logistic Regression model
  - Check impact of varying the hidden layer size, including overfitting
  
- <A href='http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week4/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step%20v8.html'>Building your Deep Neural Network - Step by Step</A><BR>
  - Build a L-layer Neural Network for image classification
  - Use non-linear activations ReLU to improve the model
  
- <A href='http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week4/Deep%20Neural%20Network%20-%20Application%20v8.html'>Deep Neural Network - Application</A><BR>    
  - Build a deep neural network that classifiesÂ cat vs. non-cat images
  - Experiment with different model architectures (number of hidden layers) and see how each one behaves
  - Analyze the mislabeled images
    
## Course 2. Improving Deep Neural Networks Hyperparameter tuning, Regularization and Optimization
- <A href = 'http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week1/Initialization/Initialization.html'> Initialization </A><BR>
  - Experiment with different initialization methods (zero initialization, random initialization, Xavier initialization and He initialization)
  - Chose a good initialization method to speed up the convergence of gradient descent, and reduce the training error

- <A href = 'http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week1/Regularization/Regularization%20-%20v3.html'> Regularization </A><BR>
  - Implement dropout and L2 regularization techniques on the model to improve the prediction accuracy on the test set
  
- <A href = 'http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week1/Gradient%20Checking/Gradient%20Checking%20v1.html'> Gradient Checking </A><BR>
  - Implement gradient checking from scratch to  verify the correctness of backpropagation implementation
  - Compare the results of backpropagation algorithm and gradient checking in L-dimension deep neural network
  
- <A href = 'http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week2/Optimization%20methods_v1.html'> Optimization Methods </A><BR>
  - Implement different optimization methods - Momentum, RMSProp and Adam to smooth out the steps of gradient descent
  - Perform mini-batch gradient descent to accelerate the convergence

- <A href = 'http://htmlpreview.github.io/?https://github.com/yumengdong/Deep_Learning_Coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week3/Tensorflow%20Tutorial.html'> Building neural network in tensorflow </A><BR>
  - Build a deep neural network to recognize numbers in sign language using TensorFlow framework
  
  
  
